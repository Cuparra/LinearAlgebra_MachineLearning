{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = ( [[5.09857609e+001 4.55445545e-001 1.37202030e-320]] )\n",
      "min  [-2619.9502923]\n"
     ]
    }
   ],
   "source": [
    "# 2.1 gradient descent\n",
    "\n",
    "# Tiago Moreira Trocoli da Cunha\n",
    "# numero: 226078\n",
    "\n",
    "import scipy.optimize as optimize\n",
    "import numpy as np\n",
    "\n",
    "# function to be minimize\n",
    "def f(params):\n",
    "    x1, x2, x3 = params\n",
    "    return -(100*(x1 - x2**2) - (x1 - 1)**2 + 90*(x2 - x3**2) - (x2 - 1)**2)\n",
    "\n",
    "# gradient of the function\n",
    "def gradient(params):\n",
    "    x1, x2, x3 = params\n",
    "    grad       = np.zeros((3,1))\n",
    "    grad[0][0] = 2*(params[0] - 51)\n",
    "    grad[1][0] = 202*params[1] - 92\n",
    "    grad[2][0] = 180*params[2]\n",
    "    return grad\n",
    "\n",
    "# convergence test\n",
    "def stopping_criteria(x_new, x_old, tol):\n",
    "    rel1 = np.absolute((x_new[0][0] - x_old[0][0])/x_old[0][0])\n",
    "    rel2 = np.absolute((x_new[1][0] - x_old[1][0])/x_old[1][0])\n",
    "    rel3 = np.absolute((x_new[2][0] - x_old[2][0])/x_old[2][0])\n",
    "    \n",
    "    if rel1 < tol and rel2 < tol and rel3 < tol:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# gradient descent\n",
    "def gradient_descent(function, alpha, tol):\n",
    "    \n",
    "    # initialize x equal to (0.5,0.5,0.5)\n",
    "    x = np.full((3,1), 0.5)\n",
    "    \n",
    "    while True:\n",
    "        grad = gradient(x)\n",
    "        x_new = x - alpha*grad\n",
    "        \n",
    "        if(stopping_criteria(x_new,x,tol)):\n",
    "            return x, f(x)\n",
    "        x = x_new\n",
    "    \n",
    "(argmin, mini) = gradient_descent(f,10**(-6),10**(-5))\n",
    "print 'x = (', argmin.T, ')'\n",
    "print 'min ', mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 2, 1, -119.56, -47.0, [-99.0, 49.39999999999998, 125.99999999999999])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2 Descida do gradiente com busca em linha\n",
    "from scipy.optimize import line_search\n",
    "\n",
    "# gradient of the function\n",
    "def grad(params):\n",
    "    x1, x2, x3 = params\n",
    "    return [2*(x1 - 51), 202*x2 - 92, 180*x3]\n",
    "\n",
    "line_search(f,grad,xk = np.array([0.5,0.5, 0.5]),pk = np.array([1,0.2,0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = ( [ 5.10000087e+01  4.55445748e-01 -5.81136440e-07] )\n",
      "min  -2619.9504950493942\n"
     ]
    }
   ],
   "source": [
    "# 2.3 L-BFGS\n",
    "\n",
    "result = optimize.minimize(f, [0.5,0.5,0.5], method = 'L-BFGS-B')\n",
    "print 'x = (', result.x, ')'\n",
    "print 'min ', f(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = ( [5.09999326e+01 4.55441931e-01 5.11734839e-06] )\n",
      "min  -2619.9504950412893\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Nelder-Mead\n",
    "\n",
    "bnds = [[-10,10], [-10,10], [-10,10]]\n",
    "result = optimize.minimize(f, [0.5,0.5,0.5], method = 'Nelder-Mead')\n",
    "print 'x = (', result.x, ')'\n",
    "print 'min ', f(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Py-BOBYQA Results ******\n",
      "Solution xmin = [1.00000000e+01 4.55445538e-01 8.28930770e-09]\n",
      "Objective value f(xmin) = -938.950495\n",
      "Needed 50 objective evaluations (at 50 points)\n",
      "Approximate gradient = [-8.20000124e+01  5.35714737e-06 -5.04696502e-06]\n",
      "Approximate Hessian = [[-281.97844229   72.97080512   45.35139857]\n",
      " [  72.97080512  717.70251729 -347.43191852]\n",
      " [  45.35139857 -347.43191852  416.09160274]]\n",
      "Exit flag = 0\n",
      "Success: rho has reached rhoend\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.5 BOBYQA\n",
    "\n",
    "# Define the starting point\n",
    "import pybobyqa\n",
    "\n",
    "# staring point\n",
    "x0 = np.array([0.5, 0.5, 0.5])\n",
    "\n",
    "# Define constraints (lower <= x <= upper)\n",
    "lower = np.array([-10.0, -10.0, -10.0])\n",
    "upper = np.array([10.0, 10.0, 10.0])\n",
    "\n",
    "# Minimize\n",
    "soln = pybobyqa.solve(f, x0, bounds=(lower,upper))\n",
    "\n",
    "# Display output\n",
    "print soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5, 0.5, -47.0]\n",
      "[10.6, -0.40000004, -8.5, 5588.62]\n",
      "[18.68, 16.880001, 144.5, 1904893.4]\n",
      "[25.144001, -314.89603, -2456.5, 553137500.0]\n",
      "[30.3152, 6055.204, 41760.5, 160657200000.0]\n",
      "[34.45216, -116250.73, -709928.5, 46724810000000.0]\n",
      "[37.761726, 2232023.2, 12068784.0, 1.3612174e+16]\n",
      "[40.40938, -42854836.0, -205169340.0, 3.9739915e+18]\n",
      "[42.527504, 822812860.0, 3487879000.0, 1.1632561e+21]\n",
      "[44.222004, -15798007000.0, -59293946000.0, 3.4162675e+23]\n"
     ]
    }
   ],
   "source": [
    "# Obs: por algum motivo, o tensorflow maximiza em vez de minimizar\n",
    "# quando ha multiplicação de minimizar quando ha multiplicação de constantes,\n",
    "# no caso, 100 e 90. tirando estas constantes, ele consegue minimizar.\n",
    "# provavelemte, teria que inicializar as constantes, procurei\n",
    "# na internet e não encontrei nada muito claro a respesto. Infelizmente,\n",
    "# não tenho dominio de TensorFlow.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x1 = tf.Variable(0.5, name='x1', dtype=tf.float32)\n",
    "x2 = tf.Variable(0.5, name='x2', dtype=tf.float32)\n",
    "x3 = tf.Variable(0.5, name='x3', dtype=tf.float32)\n",
    "\n",
    "fx = -(100*(x1 - x2*x2) - (x1 - 1)*(x1 - 1) + 90*(x2 - x3*x3) - (x2 - 1)*(x2 - 1))\n",
    "\n",
    "loss = fx\n",
    "opt  = tf.train.GradientDescentOptimizer(0.1).minimize(fx)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "   sess.run(tf.global_variables_initializer())\n",
    "   for i in range(10):\n",
    "     print(sess.run([x1,x2,x3,loss]))\n",
    "     sess.run(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5, 0.5, -0.0]\n",
      "[0.7, 0.6, 0.4, -0.53]\n",
      "[0.86, 0.66, 0.32, -0.84679997]\n",
      "[0.98800004, 0.696, 0.25599998, -1.0414879]\n",
      "[1.0904, 0.7176, 0.20479998, -1.1631852]\n",
      "[1.17232, 0.73056, 0.16383998, -1.2400265]\n",
      "[1.237856, 0.73833597, 0.13107198, -1.2888286]\n",
      "[1.2902849, 0.7430016, 0.10485759, -1.3199265]\n",
      "[1.332228, 0.745801, 0.08388607, -1.3397803]\n",
      "[1.3657824, 0.7474806, 0.067108855, -1.3524694]\n",
      "[1.3926259, 0.7484883, 0.053687084, -1.3605839]\n",
      "[1.4141008, 0.749093, 0.04294967, -1.365775]\n",
      "[1.4312806, 0.7494558, 0.034359735, -1.3690964]\n",
      "[1.4450245, 0.7496735, 0.027487788, -1.3712219]\n",
      "[1.4560196, 0.7498041, 0.02199023, -1.3725821]\n",
      "[1.4648157, 0.74988246, 0.017592184, -1.3734525]\n",
      "[1.4718525, 0.7499295, 0.014073747, -1.3740096]\n",
      "[1.4774821, 0.7499577, 0.011258998, -1.374366]\n",
      "[1.4819857, 0.7499746, 0.009007199, -1.3745944]\n",
      "[1.4855886, 0.74998474, 0.007205759, -1.3747404]\n"
     ]
    }
   ],
   "source": [
    "# sem as constantes 100 e 90, o tensorflow encontra o minimo global, -1.3749988,\n",
    "# que de acordo com o Wolphram Alpha também é -11/8 = -1.3749988.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x1 = tf.Variable(0.5, name='x1', dtype=tf.float32)\n",
    "x2 = tf.Variable(0.5, name='x2', dtype=tf.float32)\n",
    "x3 = tf.Variable(0.5, name='x3', dtype=tf.float32)\n",
    "\n",
    "fx = -((x1 - x2*x2) - (x1 - 1)*(x1 - 1) + (x2 - x3*x3) - (x2 - 1)*(x2 - 1))\n",
    "\n",
    "loss = fx\n",
    "opt  = tf.train.GradientDescentOptimizer(0.1).minimize(fx)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "   sess.run(tf.global_variables_initializer())\n",
    "   for i in range(20):\n",
    "     print(sess.run([x1,x2,x3,loss]))\n",
    "     sess.run(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
